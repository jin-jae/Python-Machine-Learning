{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# 로지스틱 회귀\n",
    "시그모이드 함수 최적선을 탐색하여, 시그모이드 함수의 반환 값을 확률로 간주에 확률에 따라 분류 결정\n",
    "\n",
    "Sigmoid Function?\n",
    "- 자연, 사회 현상에서 특정 변수의 확률 값은 선형이 아니라 시그모이드 함수의 형태를 띰.\n",
    "- x의 값에 따라 y는 0에서 1 사이의 값을 반환함.\n",
    "\n",
    "LogisticRegression class parameter: solver\n",
    "- lbfgs: 메모리 절약, CPU 연산 병렬 수행\n",
    "- liblinear: 작은 데이터 세트에 효과적으로 동작\n",
    "- newton-cg: 정교한 최적화\n",
    "- sag: Stochastic Average Gradient (경사 하강법 적용)\n",
    "- saga: sag with L1 Regularization"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### 위스콘신 유방암 데이터 세트"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "cancer = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data_scaled = scaler.fit_transform(cancer.data)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_scaled, cancer.target,\n",
    "                                                    test_size=0.3, random_state=0)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy: 0.977, roc_auc: 0.972\n"
     ]
    }
   ],
   "source": [
    "# LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "lr_clf.fit(X_train, y_train)\n",
    "lr_prds = lr_clf.predict(X_test)\n",
    "\n",
    "print(\"accuracy: {0:.3f}, roc_auc: {1:.3f}\".format(accuracy_score(y_test, lr_prds),\n",
    "                                                   roc_auc_score(y_test,lr_prds)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "solver: lbfgs, accuracy: 0.977, roc_auc:0.972\n",
      "solver: liblinear, accuracy: 0.982, roc_auc:0.979\n",
      "solver: newton-cg, accuracy: 0.977, roc_auc:0.972\n",
      "solver: sag, accuracy: 0.982, roc_auc:0.979\n",
      "solver: saga, accuracy: 0.982, roc_auc:0.979\n"
     ]
    }
   ],
   "source": [
    "# compare solver performance\n",
    "solvers = [\"lbfgs\", \"liblinear\", \"newton-cg\", \"sag\", \"saga\"]\n",
    "\n",
    "# LogisticRegression\n",
    "for solver in solvers:\n",
    "    lr_clf = LogisticRegression(solver=solver, max_iter=600)\n",
    "    lr_clf.fit(X_train, y_train)\n",
    "    lr_prds = lr_clf.predict(X_test)\n",
    "\n",
    "    print(\"solver: {0}, accuracy: {1:.3f}, roc_auc:{2:.3f}\".format(solver,\n",
    "                                                                   accuracy_score(y_test, lr_prds), roc_auc_score(y_test, lr_prds)))"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "LogisticRegression 클래스 주요 하이퍼 파라미터로 penalty, C 설정 가능 (규제 내용 및 규제 강도)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best hyper parameter: {'C': 0.1, 'penalty': 'l2', 'solver': 'liblinear'}, best mean accuracy: 0.979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 1091, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"/opt/anaconda3/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py\", line 61, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/opt/anaconda3/lib/python3.9/site-packages/sklearn/model_selection/_search.py:953: UserWarning: One or more of the test scores are non-finite: [0.96485659 0.94555834 0.92261209        nan 0.97891024 0.97364708\n",
      " 0.96131997        nan 0.97539218 0.97539218 0.96835608        nan\n",
      " 0.97011974 0.97011974 0.96662025        nan 0.96661097 0.96661097\n",
      " 0.96134781        nan]\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "params = {\n",
    "    \"solver\": [\"liblinear\", \"lbfgs\"],\n",
    "    \"penalty\": [\"l2\", \"l1\"],\n",
    "    \"C\": [0.01, 0.1, 1, 5, 10]\n",
    "}\n",
    "\n",
    "lr_clf = LogisticRegression()\n",
    "\n",
    "grid_clf = GridSearchCV(lr_clf, param_grid=params, scoring=\"accuracy\", cv=3)\n",
    "grid_clf.fit(data_scaled, cancer.target)\n",
    "print(\"best hyper parameter: {0}, best mean accuracy: {1:.3f}\".format(grid_clf.best_params_,\n",
    "                                                                      grid_clf.best_score_))"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
